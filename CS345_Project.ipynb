{"cells":[{"cell_type":"markdown","metadata":{"id":"eS8JB0zTqSBh"},"source":["# Gabriel Bertasius & Jaden Ford#\n","\n","# Predicting Game Success: A Regression Analysis on the Steam Games Dataset #"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v76KStefqSBl"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","# show all columns\n","pd.set_option('display.max_columns', None)"]},{"cell_type":"markdown","metadata":{"id":"_meUJYQmqSBm"},"source":["## Downloading and loading data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KTfayHPTqSBn"},"outputs":[],"source":["# load the data into a dataframe for easy handling\n","import os\n","DATASET_DIR = './data/'\n","DATASET_FILENAME = 'steamgames.parquet'\n","DATASET_PATH = DATASET_DIR+DATASET_FILENAME\n","DATASET_COMPRESSION = 'zstd'  # Very fast and compresses as well as gzip\n","download_data = 1\n","\n","\n","def check_file_exists(path: str) -> bool:\n","    return os.path.exists(path)\n","\n","\n","def check_data_dir_exists() -> bool:\n","    return os.path.exists(DATASET_DIR)\n","\n","\n","def create_data_dir():\n","    directory_name = DATASET_DIR\n","    try:\n","        os.mkdir(directory_name)\n","        print(f\"Directory '{directory_name}' created successfully.\")\n","    except FileExistsError:\n","        print(f\"Directory '{directory_name}' already exists.\")\n","    except PermissionError:\n","        print(f\"Permission denied: Unable to create '{directory_name}'.\")\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","\n","def download_steamgames_dataset() -> pd.DataFrame:\n","    df = pd.read_parquet(\n","        \"hf://datasets/FronkonGames/steam-games-dataset/data/train-00000-of-00001-e2ed184370a06932.parquet\")\n","    return df\n","\n","\n","def write_dataset_pqt(df: pd.DataFrame, filename: str = DATASET_FILENAME, overwrite: bool = False) -> bool:\n","    dir = DATASET_DIR\n","    path = dir+filename\n","    if (check_data_dir_exists() == False):\n","        create_data_dir()\n","    if check_file_exists(path) and overwrite == False:\n","        print(\"File exists. Pass 'overwrite' to replace.\")\n","        return False\n","    else:\n","        df.to_parquet(path, compression='zstd')\n","        return True\n","\n","\n","def read_dataset_pqt(filename: str = DATASET_FILENAME):\n","    path = DATASET_DIR+filename\n","    if check_file_exists(path):\n","        print(\"Loading dataset from local storage...\")\n","        prq = pd.read_parquet(path)\n","        print(\"✅ Local dataset loaded.\")\n","        return prq\n","    else:\n","        print(\"Parquet file not found.\")\n","\n","\n","def download_and_save_dataset(force: bool = False, filename: str = DATASET_FILENAME) -> pd.DataFrame | None:\n","    dir = DATASET_DIR\n","    path = dir+filename\n","    if (check_file_exists(path)):\n","        print(f\"⚠️ Dataset exists locally. Path:{path}\")\n","        if (force == False):\n","            print(\"Use force=True to download and overwrite.\")\n","            return None\n","        else:\n","            print(\"Redownloading and Overwriting...\")\n","    else:\n","        print(f\"Downloading and saving dataset to {path} \")\n","    df = download_steamgames_dataset()\n","    write_dataset_pqt(df, overwrite=True)\n","    print(\"✅ Done.\")\n","    print(f\"Saved to: {path}\")\n","    return df\n","\n","\n","df = download_and_save_dataset(force=False)\n","if(df is None):\n","    df = read_dataset_pqt()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7D5bIn3qSBo"},"outputs":[],"source":["# Check for any missing values\n","df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KOWcJyU2qSBo"},"outputs":[],"source":["# remove any columns that won't contribute to a game's success rating\n","cols_to_remove = ['About the game', 'Supported languages', 'Full audio languages',\n","                  'Header image', 'Website', 'Support url', 'Support email', 'Metacritic url',\n","                  'Score rank', 'Screenshots', 'Movies']\n","df = df.drop(columns=cols_to_remove, axis=1)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jPHXKeYpqSBp"},"outputs":[],"source":["# function that calculates the number of years since a game's release date\n","from datetime import datetime\n","def years_since_release(date_string):\n","  if len(date_string) == 11 or len(date_string) == 12:\n","        date = datetime.strptime(date_string, \"%b %d, %Y\")\n","  else: # length must be 8 or 9\n","      date = datetime.strptime(date_string, \"%b %Y\")\n","\n","  current_date = datetime.now()\n","  years = (current_date - date).days / 365\n","  return years\n","\n","# function to return the avg number of estimated owners\n","def est_owners(num_owners):\n","  numbers = num_owners.split('-')\n","  return (int(numbers[0]) + int(numbers[1])) / 2\n","\n","# function to normalize a numerical column between 0-1 based on min and and max values\n","def min_max_normalize(column):\n","  column = np.array(column)\n","  norm_col = ( column - np.min(column) ) / ( np.max(column) - np.min(column) )\n","  return norm_col"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EgK_WkVxqSBp"},"outputs":[],"source":["# convert release date to years since release\n","df['Release date'] = df['Release date'].apply(years_since_release)\n","\n","# return middle value for each given range of estimated owners\n","df['Estimated owners'] = df['Estimated owners'].apply(est_owners)\n","\n","# convert windows, mac, and linux columns from boolean to integer\n","df['Windows'] = df['Windows'].astype(int)\n","df['Mac'] = df['Mac'].astype(int)\n","df['Linux'] = df['Linux'].astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_-pK_l6qSBp"},"outputs":[],"source":["# Filter out any games that are free, have no peak ccu, and no estimated owners\n","# This allows us to judge success based on games that competed in certain markets, and have had actual people play them\n","no_peak_ccu_cols = df[df['Peak CCU'] == 0].index\n","df = df.drop(no_peak_ccu_cols, axis=0)\n","\n","no_est_owners_cols = df[df['Estimated owners'] == 0].index\n","df = df.drop(no_est_owners_cols, axis=0)\n","\n","no_price_cols = df[df['Price'] == 0].index\n","df = df.drop(no_price_cols, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILaokE_wqSBq"},"outputs":[],"source":["# normalize any large value ranges\n","cols_to_normalize = ['Release date', 'Estimated owners', 'Peak CCU', 'Required age', 'Price', 'DLC count',\n","                     'Metacritic score', 'User score', 'Positive', 'Negative', 'Achievements',\n","                     'Recommendations', 'Average playtime forever', 'Average playtime two weeks',\n","                     'Median playtime forever', 'Median playtime two weeks']\n","for col in cols_to_normalize:\n","  df[col] = min_max_normalize(df[col])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgC5ukZtqSBq"},"outputs":[],"source":["# If we want to remove rows that have no reviews, we would have 4269 examples\n","#df = df.dropna(axis=0, subset='Reviews')\n","#print(df.shape[0])\n","#df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F60-TuWMqSBq"},"outputs":[],"source":["print(df.shape)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"bPofcoqyqSBq"},"source":["### Counting unique words in Categories, Genres, Tags\n","\n","'Dumb counting' as in the tags 'turn-based' and 'turn-based combat' or 'turn-based strategy' are different words. These should be ok for word2vec as they're similar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WSoDCRZqSBr"},"outputs":[],"source":["df.columns\n","df['Tags']\n","\n","def count_unique_words(df, label:str):\n","    lists:pd.Series= df[label].str.casefold().str.split(',')\n","    words = set()\n","    [words.update(x) for x in lists if x is not None]\n","    print(f\"Number of unique {label}: {len(words)}\")\n","    return words\n","\n","count_unique_words(df, 'Categories') # 39\n","count_unique_words(df, 'Genres') # 27\n","count_unique_words(df, 'Tags') # 444\n"]},{"cell_type":"code","source":["encoded_categories = df['Categories'].str.get_dummies(sep=',')\n","encoded_genres = df['Genres'].str.get_dummies(sep=',')\n","\n","df = pd.concat([df, encoded_categories, encoded_genres], axis=1)\n","df = df.drop(columns=['Categories', 'Genres'], axis=1)"],"metadata":{"id":"LtwBNGg36M_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df.shape)\n","df.head()"],"metadata":{"id":"9WhRkLL7zfGv"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1CD4EsTokInoL8rrk7tV9dBVteDf4sZ2l","timestamp":1731559683460}]},"kernelspec":{"display_name":"steamgames","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gabriel Bertasius & Jaden Ford#\n",
    "\n",
    "# Predicting Game Success: A Regression Analysis on the Steam Games Dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into a dataframe for easy handling\n",
    "import os\n",
    "DATASET_DIR = './data/'\n",
    "DATASET_FILENAME = 'steamgames.parquet'\n",
    "DATASET_PATH = DATASET_DIR+DATASET_FILENAME\n",
    "DATASET_COMPRESSION = 'zstd'  # Very fast and compresses as well as gzip\n",
    "download_data = 1\n",
    "\n",
    "\n",
    "def check_file_exists(path: str) -> bool:\n",
    "    return os.path.exists(path)\n",
    "\n",
    "\n",
    "def check_data_dir_exists() -> bool:\n",
    "    return os.path.exists(DATASET_DIR)\n",
    "\n",
    "\n",
    "def create_data_dir():\n",
    "    directory_name = DATASET_DIR\n",
    "    try:\n",
    "        os.mkdir(directory_name)\n",
    "        print(f\"Directory '{directory_name}' created successfully.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Directory '{directory_name}' already exists.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: Unable to create '{directory_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "def download_steamgames_dataset() -> pd.DataFrame:\n",
    "    df = pd.read_parquet(\n",
    "        \"hf://datasets/FronkonGames/steam-games-dataset/data/train-00000-of-00001-e2ed184370a06932.parquet\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_dataset_pqt(df: pd.DataFrame, filename: str = DATASET_FILENAME, overwrite: bool = False) -> bool:\n",
    "    dir = DATASET_DIR\n",
    "    path = dir+filename\n",
    "    if (check_data_dir_exists() == False):\n",
    "        create_data_dir()\n",
    "    if check_file_exists(path) and overwrite == False:\n",
    "        print(\"File exists. Pass 'overwrite' to replace.\")\n",
    "        return False\n",
    "    else:\n",
    "        df.to_parquet(path, compression='zstd')\n",
    "        return True\n",
    "\n",
    "\n",
    "def read_dataset_pqt(filename: str = DATASET_FILENAME):\n",
    "    path = DATASET_DIR+filename\n",
    "    if check_file_exists(path):\n",
    "        print(\"Loading dataset from local storage...\")\n",
    "        prq = pd.read_parquet(path)\n",
    "        print(\"✅ Local dataset loaded.\")\n",
    "        return prq\n",
    "    else:\n",
    "        print(\"Parquet file not found.\")\n",
    "\n",
    "\n",
    "def download_and_save_dataset(force: bool = False, filename: str = DATASET_FILENAME) -> pd.DataFrame | None:\n",
    "    dir = DATASET_DIR\n",
    "    path = dir+filename\n",
    "    if (check_file_exists(path)):\n",
    "        print(f\"⚠️ Dataset exists locally. Path:{path}\")\n",
    "        if (force == False):\n",
    "            print(\"Use force=True to download and overwrite.\")\n",
    "            return None\n",
    "        else:\n",
    "            print(\"Redownloading and Overwriting...\")\n",
    "    else:\n",
    "        print(f\"Downloading and saving dataset to {path} \")\n",
    "    df = download_steamgames_dataset()\n",
    "    write_dataset_pqt(df, overwrite=True)\n",
    "    print(\"✅ Done.\")\n",
    "    print(f\"Saved to: {path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "df = download_and_save_dataset(force=False)\n",
    "if(df is None):\n",
    "    df = read_dataset_pqt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any columns that won't contribute to a game's success rating\n",
    "cols_to_remove = ['About the game', 'Supported languages', 'Full audio languages',\n",
    "                  'Header image', 'Website', 'Support url', 'Support email', 'Metacritic url',\n",
    "                  'Score rank', 'Screenshots', 'Movies']\n",
    "df = df.drop(columns=cols_to_remove, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that calculates the number of years since a game's release date\n",
    "from datetime import datetime\n",
    "def years_since_release(date_string):\n",
    "  if len(date_string) == 11 or len(date_string) == 12:\n",
    "        date = datetime.strptime(date_string, \"%b %d, %Y\")\n",
    "  else: # length must be 8 or 9\n",
    "      date = datetime.strptime(date_string, \"%b %Y\")\n",
    "\n",
    "  current_date = datetime.now()\n",
    "  years = (current_date - date).days / 365\n",
    "  return years\n",
    "\n",
    "# function to return the avg number of estimated owners\n",
    "def est_owners(num_owners):\n",
    "  numbers = num_owners.split('-')\n",
    "  return (int(numbers[0]) + int(numbers[1])) / 2\n",
    "\n",
    "# function to normalize a numerical column between 0-1 based on min and and max values\n",
    "def min_max_normalize(column):\n",
    "  column = np.array(column)\n",
    "  norm_col = ( column - np.min(column) ) / ( np.max(column) - np.min(column) )\n",
    "  return norm_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert release date to years since release\n",
    "df['Release date'] = df['Release date'].apply(years_since_release)\n",
    "\n",
    "# return middle value for each given range of estimated owners\n",
    "df['Estimated owners'] = df['Estimated owners'].apply(est_owners)\n",
    "\n",
    "# convert windows, mac, and linux columns from boolean to integer\n",
    "df['Windows'] = df['Windows'].astype(int)\n",
    "df['Mac'] = df['Mac'].astype(int)\n",
    "df['Linux'] = df['Linux'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out any games that are free, have no peak ccu, and no estimated owners\n",
    "# This allows us to judge success based on games that competed in certain markets, and have had actual people play them\n",
    "no_peak_ccu_cols = df[df['Peak CCU'] == 0].index\n",
    "df = df.drop(no_peak_ccu_cols, axis=0)\n",
    "\n",
    "no_est_owners_cols = df[df['Estimated owners'] == 0].index\n",
    "df = df.drop(no_est_owners_cols, axis=0)\n",
    "\n",
    "no_price_cols = df[df['Price'] == 0].index\n",
    "df = df.drop(no_price_cols, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize any large value ranges\n",
    "cols_to_normalize = ['Release date', 'Estimated owners', 'Peak CCU', 'Required age', 'Price', 'DLC count',\n",
    "                     'Metacritic score', 'User score', 'Positive', 'Negative', 'Achievements',\n",
    "                     'Recommendations', 'Average playtime forever', 'Average playtime two weeks',\n",
    "                     'Median playtime forever', 'Median playtime two weeks']\n",
    "for col in cols_to_normalize:\n",
    "  df[col] = min_max_normalize(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to remove rows that have no reviews, we would have 4269 examples\n",
    "#df = df.dropna(axis=0, subset='Reviews')\n",
    "#print(df.shape[0])\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting unique words in Categories, Genres, Tags\n",
    "\n",
    "'Dumb counting' as in the tags 'turn-based' and 'turn-based combat' or 'turn-based strategy' are different words. These should be ok for word2vec as they're similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df['Tags']\n",
    "\n",
    "def count_unique_words(df, label:str):\n",
    "    lists:pd.Series= df[label].str.casefold().str.split(',')\n",
    "    words = set()\n",
    "    [words.update(x) for x in lists if x is not None]\n",
    "    print(f\"Number of unique {label}: {len(words)}\")\n",
    "    return words\n",
    "\n",
    "count_unique_words(df, 'Categories') # 39\n",
    "count_unique_words(df, 'Genres') # 27\n",
    "count_unique_words(df, 'Tags') # 444\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_categories = df['Categories'].str.get_dummies(sep=',')\n",
    "encoded_genres = df['Genres'].str.get_dummies(sep=',')\n",
    "\n",
    "df = pd.concat([df, encoded_categories, encoded_genres], axis=1)\n",
    "df = df.drop(columns=['Categories', 'Genres'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1CD4EsTokInoL8rrk7tV9dBVteDf4sZ2l",
     "timestamp": 1731559683460
    }
   ]
  },
  "kernelspec": {
   "display_name": "steamgames",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
