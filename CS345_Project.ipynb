{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gabriel Bertasius & Jaden Ford#\n",
    "\n",
    "# Predicting Game Success: A Regression Analysis on the Steam Games Dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Dataset exists locally. Path:./data/steamgames.parquet\n",
      "Use force=True to download and overwrite.\n",
      "Loading dataset from local storage...\n",
      "✅ Local dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "# load the data into a dataframe for easy handling\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import gzip\n",
    "DATASET_DIR = './data/'\n",
    "DATASET_FILENAME = 'steamgames.parquet'\n",
    "DATASET_PATH = DATASET_DIR+DATASET_FILENAME\n",
    "DATASET_COMPRESSION = 'zstd'  # Very fast and compresses as well as gzip\n",
    "MODELS_DIR = './models/'\n",
    "MODELS_FILENAME = 'model-'\n",
    "download_data = 1\n",
    "\n",
    "\n",
    "def check_file_exists(path: str) -> bool:\n",
    "    return os.path.exists(path)\n",
    "\n",
    "\n",
    "def check_data_dir_exists() -> bool:\n",
    "    return os.path.exists(DATASET_DIR)\n",
    "\n",
    "def check_models_dir_exists() -> bool:\n",
    "    return os.path.exists(MODELS_DIR)\n",
    "\n",
    "def create_data_dir():\n",
    "    directory_name = DATASET_DIR\n",
    "    try:\n",
    "        os.mkdir(directory_name)\n",
    "        print(f\"Directory '{directory_name}' created successfully.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Directory '{directory_name}' already exists.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: Unable to create '{directory_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def create_models_dir():\n",
    "    directory_name = MODELS_DIR \n",
    "    try:\n",
    "        os.mkdir(directory_name)\n",
    "        print(f\"Directory '{directory_name}' created successfully.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Directory '{directory_name}' already exists.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: Unable to create '{directory_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def download_steamgames_dataset() -> pd.DataFrame:\n",
    "    df = pd.read_parquet(\n",
    "        \"hf://datasets/FronkonGames/steam-games-dataset/data/train-00000-of-00001-e2ed184370a06932.parquet\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_dataset_pqt(df: pd.DataFrame, filename: str = DATASET_FILENAME, overwrite: bool = False) -> bool:\n",
    "    dir = DATASET_DIR\n",
    "    path = dir+filename\n",
    "    if (check_data_dir_exists() == False):\n",
    "        create_data_dir()\n",
    "    if check_file_exists(path) and overwrite == False:\n",
    "        print(\"File exists. Pass 'overwrite' to replace.\")\n",
    "        return False\n",
    "    else:\n",
    "        df.to_parquet(path, compression='zstd')\n",
    "        return True\n",
    "\n",
    "\n",
    "def read_dataset_pqt(filename: str = DATASET_FILENAME):\n",
    "    path = DATASET_DIR+filename\n",
    "    if check_file_exists(path):\n",
    "        print(\"Loading dataset from local storage...\")\n",
    "        prq = pd.read_parquet(path)\n",
    "        print(\"✅ Local dataset loaded.\")\n",
    "        return prq\n",
    "    else:\n",
    "        print(\"Parquet file not found.\")\n",
    "\n",
    "def datestamp():\n",
    "    \"\"\" Get the current datestamp \"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def write_model_log(path:str, config: dict, **kwargs):\n",
    "    with open(path+\".txt\", \"a\") as file:\n",
    "        file.write(f\"[{datestamp()}]\\n\")\n",
    "        file.write(f\"{config}\\n\")\n",
    "        if kwargs:\n",
    "            for x in kwargs:\n",
    "                file.write(f\"{x}\\n\")\n",
    "    \n",
    "def pickle_model(filename: str, model, params_dict:dict, param_grid:dict = None,overwrite: bool=False, **extra_data):\n",
    "    dir = MODELS_DIR \n",
    "    path = dir+filename\n",
    "    for s in params_dict.values():\n",
    "        path += f'-{s}'\n",
    "    if (check_models_dir_exists() == False):\n",
    "        create_models_dir()\n",
    "    if check_file_exists(path) and overwrite == False:\n",
    "        print(\"File exists. Pass 'overwrite' to replace.\")\n",
    "        return False\n",
    "    else:\n",
    "        if param_grid is not None:\n",
    "            write_model_log(path, param_grid, **extra_data)\n",
    "        else:\n",
    "            write_model_log(path, params_dict)\n",
    "        level = 7   # Good balance between speed and compression\n",
    "        with gzip.open(path+\".pkl.gz\", \"wb\", compresslevel=level) as file:\n",
    "            pickle.dump(model, file, protocol=5)\n",
    "        return True\n",
    "\n",
    "def unpickle_model(filename):\n",
    "    path = MODELS_DIR+filename\n",
    "    with gzip.open(path+\".pkl.gz\", \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "    \n",
    "def download_and_save_dataset(force: bool = False, filename: str = DATASET_FILENAME) -> pd.DataFrame | None:\n",
    "    dir = DATASET_DIR\n",
    "    path = dir+filename\n",
    "    if (check_file_exists(path)):\n",
    "        print(f\"⚠️ Dataset exists locally. Path:{path}\")\n",
    "        if (force == False):\n",
    "            print(\"Use force=True to download and overwrite.\")\n",
    "            return None\n",
    "        else:\n",
    "            print(\"Redownloading and Overwriting...\")\n",
    "    else:\n",
    "        print(f\"Downloading and saving dataset to {path} \")\n",
    "    df = download_steamgames_dataset()\n",
    "    write_dataset_pqt(df, overwrite=False)\n",
    "    print(\"✅ Done.\")\n",
    "    print(f\"Saved to: {path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "df = download_and_save_dataset(force=False)\n",
    "if(df is None):\n",
    "    df = read_dataset_pqt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  6\n",
       "About the game     3437\n",
       "Reviews           73844\n",
       "Website           44506\n",
       "Support url       42544\n",
       "Support email     13319\n",
       "Metacritic url    79650\n",
       "Score rank        83516\n",
       "Notes             70845\n",
       "Developers         3457\n",
       "Publishers         3705\n",
       "Categories         4456\n",
       "Genres             3425\n",
       "Tags              19986\n",
       "Screenshots        1926\n",
       "Movies             6300\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any missing values\n",
    "sum = df.isnull().sum()\n",
    "sum[sum != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AppID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Estimated owners</th>\n",
       "      <th>Peak CCU</th>\n",
       "      <th>Required age</th>\n",
       "      <th>Price</th>\n",
       "      <th>DLC count</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Windows</th>\n",
       "      <th>Mac</th>\n",
       "      <th>Linux</th>\n",
       "      <th>Metacritic score</th>\n",
       "      <th>User score</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Achievements</th>\n",
       "      <th>Recommendations</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Average playtime forever</th>\n",
       "      <th>Average playtime two weeks</th>\n",
       "      <th>Median playtime forever</th>\n",
       "      <th>Median playtime two weeks</th>\n",
       "      <th>Developers</th>\n",
       "      <th>Publishers</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200</td>\n",
       "      <td>Galactic Bowling</td>\n",
       "      <td>Oct 21, 2008</td>\n",
       "      <td>0 - 20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Perpetual FX Creative</td>\n",
       "      <td>Perpetual FX Creative</td>\n",
       "      <td>Single-player,Multi-player,Steam Achievements,...</td>\n",
       "      <td>Casual,Indie,Sports</td>\n",
       "      <td>Indie,Casual,Sports,Bowling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>655370</td>\n",
       "      <td>Train Bandit</td>\n",
       "      <td>Oct 12, 2017</td>\n",
       "      <td>0 - 20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rusty Moyher</td>\n",
       "      <td>Wild Rooster</td>\n",
       "      <td>Single-player,Steam Achievements,Full controll...</td>\n",
       "      <td>Action,Indie</td>\n",
       "      <td>Indie,Action,Pixel Graphics,2D,Retro,Arcade,Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1732930</td>\n",
       "      <td>Jolt Project</td>\n",
       "      <td>Nov 17, 2021</td>\n",
       "      <td>0 - 20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Campião Games</td>\n",
       "      <td>Campião Games</td>\n",
       "      <td>Single-player</td>\n",
       "      <td>Action,Adventure,Indie,Strategy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1355720</td>\n",
       "      <td>Henosis™</td>\n",
       "      <td>Jul 23, 2020</td>\n",
       "      <td>0 - 20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Odd Critter Games</td>\n",
       "      <td>Odd Critter Games</td>\n",
       "      <td>Single-player,Full controller support</td>\n",
       "      <td>Adventure,Casual,Indie</td>\n",
       "      <td>2D Platformer,Atmospheric,Surreal,Mystery,Puzz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1139950</td>\n",
       "      <td>Two Weeks in Painland</td>\n",
       "      <td>Feb 3, 2020</td>\n",
       "      <td>0 - 20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>This Game may contain content not appropriate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unusual Games</td>\n",
       "      <td>Unusual Games</td>\n",
       "      <td>Single-player,Steam Achievements</td>\n",
       "      <td>Adventure,Indie</td>\n",
       "      <td>Indie,Adventure,Nudity,Violent,Sexual Content,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AppID                   Name  Release date Estimated owners  Peak CCU  \\\n",
       "0    20200       Galactic Bowling  Oct 21, 2008        0 - 20000         0   \n",
       "1   655370           Train Bandit  Oct 12, 2017        0 - 20000         0   \n",
       "2  1732930           Jolt Project  Nov 17, 2021        0 - 20000         0   \n",
       "3  1355720               Henosis™  Jul 23, 2020        0 - 20000         0   \n",
       "4  1139950  Two Weeks in Painland   Feb 3, 2020        0 - 20000         0   \n",
       "\n",
       "   Required age  Price  DLC count Reviews  Windows    Mac  Linux  \\\n",
       "0             0  19.99          0    None     True  False  False   \n",
       "1             0   0.99          0    None     True   True  False   \n",
       "2             0   4.99          0    None     True  False  False   \n",
       "3             0   5.99          0    None     True   True   True   \n",
       "4             0   0.00          0    None     True   True  False   \n",
       "\n",
       "   Metacritic score  User score  Positive  Negative  Achievements  \\\n",
       "0                 0           0         6        11            30   \n",
       "1                 0           0        53         5            12   \n",
       "2                 0           0         0         0             0   \n",
       "3                 0           0         3         0             0   \n",
       "4                 0           0        50         8            17   \n",
       "\n",
       "   Recommendations                                              Notes  \\\n",
       "0                0                                               None   \n",
       "1                0                                               None   \n",
       "2                0                                               None   \n",
       "3                0                                               None   \n",
       "4                0  This Game may contain content not appropriate ...   \n",
       "\n",
       "   Average playtime forever  Average playtime two weeks  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "\n",
       "   Median playtime forever  Median playtime two weeks             Developers  \\\n",
       "0                        0                          0  Perpetual FX Creative   \n",
       "1                        0                          0           Rusty Moyher   \n",
       "2                        0                          0          Campião Games   \n",
       "3                        0                          0      Odd Critter Games   \n",
       "4                        0                          0          Unusual Games   \n",
       "\n",
       "              Publishers                                         Categories  \\\n",
       "0  Perpetual FX Creative  Single-player,Multi-player,Steam Achievements,...   \n",
       "1           Wild Rooster  Single-player,Steam Achievements,Full controll...   \n",
       "2          Campião Games                                      Single-player   \n",
       "3      Odd Critter Games              Single-player,Full controller support   \n",
       "4          Unusual Games                   Single-player,Steam Achievements   \n",
       "\n",
       "                            Genres  \\\n",
       "0              Casual,Indie,Sports   \n",
       "1                     Action,Indie   \n",
       "2  Action,Adventure,Indie,Strategy   \n",
       "3           Adventure,Casual,Indie   \n",
       "4                  Adventure,Indie   \n",
       "\n",
       "                                                Tags  \n",
       "0                        Indie,Casual,Sports,Bowling  \n",
       "1  Indie,Action,Pixel Graphics,2D,Retro,Arcade,Sc...  \n",
       "2                                               None  \n",
       "3  2D Platformer,Atmospheric,Surreal,Mystery,Puzz...  \n",
       "4  Indie,Adventure,Nudity,Violent,Sexual Content,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove any columns that won't contribute to a game's success rating\n",
    "cols_to_remove = ['About the game', 'Supported languages', 'Full audio languages',\n",
    "                  'Header image', 'Website', 'Support url', 'Support email', 'Metacritic url',\n",
    "                  'Score rank', 'Screenshots', 'Movies']\n",
    "df = df.drop(columns=cols_to_remove, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing data and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that calculates the number of years since a game's release date\n",
    "from datetime import datetime\n",
    "def years_since_release(date_string):\n",
    "  if len(date_string) == 11 or len(date_string) == 12:\n",
    "        date = datetime.strptime(date_string, \"%b %d, %Y\")\n",
    "  else: # length must be 8 or 9\n",
    "      date = datetime.strptime(date_string, \"%b %Y\")\n",
    "\n",
    "  current_date = datetime.now()\n",
    "  years = (current_date - date).days / 365\n",
    "  return years\n",
    "\n",
    "# function to return the avg number of estimated owners\n",
    "def est_owners(num_owners):\n",
    "  numbers = num_owners.split('-')\n",
    "  return (int(numbers[0]) + int(numbers[1])) / 2\n",
    "\n",
    "# function to normalize a numerical column between 0-1 based on min and and max values\n",
    "def min_max_normalize(column):\n",
    "  column = np.array(column)\n",
    "  norm_col = ( column - np.min(column) ) / ( np.max(column) - np.min(column) )\n",
    "  return norm_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert release date to years since release\n",
    "df['Release date'] = df['Release date'].apply(years_since_release)\n",
    "\n",
    "# return middle value for each given range of estimated owners\n",
    "df['Estimated owners'] = df['Estimated owners'].apply(est_owners)\n",
    "\n",
    "# convert windows, mac, and linux columns from boolean to integer\n",
    "df['Windows'] = df['Windows'].astype(int)\n",
    "df['Mac'] = df['Mac'].astype(int)\n",
    "df['Linux'] = df['Linux'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out any games that are free, have no peak ccu, and no estimated owners\n",
    "# This allows us to judge success based on games that competed in certain markets, and have had actual people play them\n",
    "no_peak_ccu_cols = df[df['Peak CCU'] == 0].index\n",
    "df = df.drop(no_peak_ccu_cols, axis=0)\n",
    "\n",
    "no_est_owners_cols = df[df['Estimated owners'] == 0].index\n",
    "df = df.drop(no_est_owners_cols, axis=0)\n",
    "\n",
    "no_price_cols = df[df['Price'] == 0].index\n",
    "df = df.drop(no_price_cols, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for later use in sentiment analysis and model performance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a copy of pre_normalized values\n",
    "df_orig = df.copy(deep=True)\n",
    "\n",
    "# store reviews for sentiment analysis\n",
    "df_reviews = df['Reviews'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize any large value ranges\n",
    "cols_to_normalize = ['Release date', 'Estimated owners', 'Peak CCU', 'Required age', 'Price', 'DLC count',\n",
    "                     'Metacritic score', 'User score', 'Positive', 'Negative', 'Achievements',\n",
    "                     'Recommendations', 'Average playtime forever', 'Average playtime two weeks',\n",
    "                     'Median playtime forever', 'Median playtime two weeks']\n",
    "for col in cols_to_normalize:\n",
    "  df[col] = min_max_normalize(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to remove rows that have no reviews, we would have 4269 examples\n",
    "#df = df.dropna(axis=0, subset='Reviews')\n",
    "#print(df.shape[0])\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20194, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AppID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Estimated owners</th>\n",
       "      <th>Peak CCU</th>\n",
       "      <th>Required age</th>\n",
       "      <th>Price</th>\n",
       "      <th>DLC count</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Windows</th>\n",
       "      <th>Mac</th>\n",
       "      <th>Linux</th>\n",
       "      <th>Metacritic score</th>\n",
       "      <th>User score</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Achievements</th>\n",
       "      <th>Recommendations</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Average playtime forever</th>\n",
       "      <th>Average playtime two weeks</th>\n",
       "      <th>Median playtime forever</th>\n",
       "      <th>Median playtime two weeks</th>\n",
       "      <th>Developers</th>\n",
       "      <th>Publishers</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1659180</td>\n",
       "      <td>TD Worlds</td>\n",
       "      <td>0.071606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039460</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MAKSIM VOLKAU</td>\n",
       "      <td>MAKSIM VOLKAU</td>\n",
       "      <td>Single-player,Steam Achievements,Steam Cloud</td>\n",
       "      <td>Indie,Strategy</td>\n",
       "      <td>Tower Defense,Rogue-lite,RTS,Replay Value,Perm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1968760</td>\n",
       "      <td>Legend of Rome - The Wrath of Mars</td>\n",
       "      <td>0.059585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>magnussoft</td>\n",
       "      <td>magnussoft</td>\n",
       "      <td>Single-player,Steam Cloud</td>\n",
       "      <td>Casual</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1178150</td>\n",
       "      <td>MazM: Jekyll and Hyde</td>\n",
       "      <td>0.138653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Growing Seeds</td>\n",
       "      <td>CFK Co., Ltd.</td>\n",
       "      <td>Single-player,Steam Achievements,Full controll...</td>\n",
       "      <td>Adventure,RPG,Simulation,Strategy</td>\n",
       "      <td>Adventure,Simulation,RPG,Strategy,Singleplayer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1026420</td>\n",
       "      <td>WARSAW</td>\n",
       "      <td>0.157617</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>“New WW2 Strategy Game Offers A Harrowing Look...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pixelated Milk</td>\n",
       "      <td>Pixelated Milk,gaming company</td>\n",
       "      <td>Single-player,Steam Achievements,Steam Trading...</td>\n",
       "      <td>Indie,RPG</td>\n",
       "      <td>Tactical RPG,Turn-Based Strategy,Wargame,Histo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1454010</td>\n",
       "      <td>Diary of Lucie</td>\n",
       "      <td>0.114093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Parange Project</td>\n",
       "      <td>Parange Project</td>\n",
       "      <td>Single-player,Partial Controller Support,Steam...</td>\n",
       "      <td>Action,Adventure,Indie,RPG,Strategy,Early Access</td>\n",
       "      <td>Action Roguelike,Action,Rogue-lite,RPGMaker,My...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AppID                                Name  Release date  \\\n",
       "6   1659180                           TD Worlds      0.071606   \n",
       "7   1968760  Legend of Rome - The Wrath of Mars      0.059585   \n",
       "8   1178150               MazM: Jekyll and Hyde      0.138653   \n",
       "10  1026420                              WARSAW      0.157617   \n",
       "14  1454010                      Diary of Lucie      0.114093   \n",
       "\n",
       "    Estimated owners  Peak CCU  Required age     Price  DLC count  \\\n",
       "6           0.000000  0.000002           0.0  0.039460   0.000423   \n",
       "7           0.000000  0.000001           0.0  0.035751   0.000000   \n",
       "8           0.000000  0.000000           0.0  0.054295   0.000000   \n",
       "10          0.000333  0.000005           0.0  0.087672   0.000000   \n",
       "14          0.000000  0.000002           0.0  0.046877   0.000000   \n",
       "\n",
       "                                              Reviews  Windows  Mac  Linux  \\\n",
       "6                                                None        1    0      0   \n",
       "7                                                None        1    0      0   \n",
       "8                                                None        1    0      0   \n",
       "10  “New WW2 Strategy Game Offers A Harrowing Look...        1    0      0   \n",
       "14                                               None        1    0      0   \n",
       "\n",
       "    Metacritic score  User score  Positive  Negative  Achievements  \\\n",
       "6           0.000000         0.0  0.000022  0.000051      0.006313   \n",
       "7           0.000000         0.0  0.000000  0.000000      0.000000   \n",
       "8           0.000000         0.0  0.000079  0.000043      0.002546   \n",
       "10          0.639175         0.0  0.000610  0.001530      0.003462   \n",
       "14          0.000000         0.0  0.000104  0.000036      0.000000   \n",
       "\n",
       "    Recommendations Notes  Average playtime forever  \\\n",
       "6          0.000000  None                   0.00000   \n",
       "7          0.000000  None                   0.00000   \n",
       "8          0.000000  None                   0.00000   \n",
       "10         0.000475  None                   0.00046   \n",
       "14         0.000000  None                   0.00000   \n",
       "\n",
       "    Average playtime two weeks  Median playtime forever  \\\n",
       "6                          0.0                 0.000000   \n",
       "7                          0.0                 0.000000   \n",
       "8                          0.0                 0.000000   \n",
       "10                         0.0                 0.000446   \n",
       "14                         0.0                 0.000000   \n",
       "\n",
       "    Median playtime two weeks       Developers                     Publishers  \\\n",
       "6                         0.0    MAKSIM VOLKAU                  MAKSIM VOLKAU   \n",
       "7                         0.0       magnussoft                     magnussoft   \n",
       "8                         0.0    Growing Seeds                  CFK Co., Ltd.   \n",
       "10                        0.0   Pixelated Milk  Pixelated Milk,gaming company   \n",
       "14                        0.0  Parange Project                Parange Project   \n",
       "\n",
       "                                           Categories  \\\n",
       "6        Single-player,Steam Achievements,Steam Cloud   \n",
       "7                           Single-player,Steam Cloud   \n",
       "8   Single-player,Steam Achievements,Full controll...   \n",
       "10  Single-player,Steam Achievements,Steam Trading...   \n",
       "14  Single-player,Partial Controller Support,Steam...   \n",
       "\n",
       "                                              Genres  \\\n",
       "6                                     Indie,Strategy   \n",
       "7                                             Casual   \n",
       "8                  Adventure,RPG,Simulation,Strategy   \n",
       "10                                         Indie,RPG   \n",
       "14  Action,Adventure,Indie,RPG,Strategy,Early Access   \n",
       "\n",
       "                                                 Tags  \n",
       "6   Tower Defense,Rogue-lite,RTS,Replay Value,Perm...  \n",
       "7                                                None  \n",
       "8   Adventure,Simulation,RPG,Strategy,Singleplayer...  \n",
       "10  Tactical RPG,Turn-Based Strategy,Wargame,Histo...  \n",
       "14  Action Roguelike,Action,Rogue-lite,RPGMaker,My...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting unique words in Categories, Genres, Tags\n",
    "\n",
    "'Dumb counting' as in the tags 'turn-based' and 'turn-based combat' or 'turn-based strategy' are different words. These should be ok for word2vec as they're similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Categories: 39\n",
      "Number of unique Genres: 27\n",
      "Number of unique Tags: 444\n"
     ]
    }
   ],
   "source": [
    "def count_unique_words(df, label:str):\n",
    "    lists:pd.Series= df[label].str.casefold().str.split(',')\n",
    "    words = set()\n",
    "    [words.update(x) for x in lists if x is not None]\n",
    "    \n",
    "    print(f\"Number of unique {label}: {len(words)}\")\n",
    "    return len(words),words\n",
    "\n",
    "count_unique_words(df_orig, 'Categories') # 39\n",
    "count_unique_words(df_orig, 'Genres') # 27\n",
    "tags_count_unique, tags_list_unique = count_unique_words(df_orig, 'Tags') # 444\n",
    "pass;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding Catergories and Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Categories'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Dev\\Anaconda3\\envs\\steamgames\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Categories'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoded_categories \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategories\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mget_dummies(sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m encoded_genres \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mget_dummies(sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, encoded_categories, encoded_genres], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Dev\\Anaconda3\\envs\\steamgames\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Dev\\Anaconda3\\envs\\steamgames\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Categories'"
     ]
    }
   ],
   "source": [
    "encoded_categories = df['Categories'].str.get_dummies(sep=',')\n",
    "encoded_genres = df['Genres'].str.get_dummies(sep=',')\n",
    "\n",
    "df = pd.concat([df, encoded_categories, encoded_genres], axis=1)\n",
    "df = df.drop(columns=['Categories', 'Genres'], axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagProcessor:\n",
    "    def __init__(self, df: pd.DataFrame, label: str):\n",
    "        self.df: pd.DataFrame = df\n",
    "        self.label: str = label\n",
    "        self.tags_series: pd.Series = self.df[self.label].str.casefold().str.split(',')\n",
    "        self.tags_series: pd.Series = self.tags_series.apply(lambda x: ['none'] if x is None else x)\n",
    "        self.tags_dict: dict = {}\n",
    "        self.total_occurrences: int = 0\n",
    "        self.sentences: list = [sentence for sentence in self.tags_series]\n",
    "\n",
    "        self.initialize_tags()\n",
    "        self.count_tags() \n",
    "\n",
    "    def initialize_tags(self):\n",
    "        tags_list_unique = set(\n",
    "            tag for sublist in self.tags_series if sublist is not None for tag in sublist)\n",
    "        self.tags_dict = {x: 0 for x in tags_list_unique}\n",
    "\n",
    "    def count_tags(self):\n",
    "        word_list = [\n",
    "            y for x in self.tags_series if x is not None for y in x]\n",
    "        self.total_occurrences = len(word_list)\n",
    "        for x in word_list:\n",
    "            self.tags_dict[x] += 1\n",
    "\n",
    "    def get_sorted_tags(self):\n",
    "        return sorted(self.tags_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    def calculate_frequencies(self):\n",
    "        return {x: y / self.total_occurrences * 100 for x, y in self.tags_dict.items()}\n",
    "\n",
    "    def get_sorted_frequencies(self):\n",
    "        word_freq = self.calculate_frequencies()\n",
    "        return sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    def stringify_tags(self):\n",
    "        str_sentences = [[', '.join(x)] for x in self.sentences]\n",
    "        str_sentences = [f'{x[0]}' for x in str_sentences]\n",
    "        return str_sentences\n",
    "\n",
    "tag_processor: TagProcessor = TagProcessor(df_orig, 'Tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting relative similarity of tags using cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the similarity of tags for each game allows provides a measure of which games are using similar tags. This will serve as a basis for performing word2vec hyperparameter optimization to obtain the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dev\\Anaconda3\\envs\\steamgames\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Custom tokenizer to treat phrases as one word\n",
    "custom_tokenizer = lambda text: [word.strip() for word in text.split(',')]\n",
    "# Perform Vectorization of tags\n",
    "count_vectorizer:CountVectorizer = CountVectorizer(input='content', tokenizer=custom_tokenizer, stop_words=['none'])\n",
    "count_vector = count_vectorizer.fit_transform(tag_processor.stringify_tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444, 445)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.get_feature_names_out()), len(tag_processor.tags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AppID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Estimated owners</th>\n",
       "      <th>Peak CCU</th>\n",
       "      <th>Required age</th>\n",
       "      <th>Price</th>\n",
       "      <th>DLC count</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Windows</th>\n",
       "      <th>Mac</th>\n",
       "      <th>Linux</th>\n",
       "      <th>Metacritic score</th>\n",
       "      <th>User score</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Achievements</th>\n",
       "      <th>Recommendations</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Average playtime forever</th>\n",
       "      <th>Average playtime two weeks</th>\n",
       "      <th>Median playtime forever</th>\n",
       "      <th>Median playtime two weeks</th>\n",
       "      <th>Developers</th>\n",
       "      <th>Publishers</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29670</th>\n",
       "      <td>42700</td>\n",
       "      <td>Call of Duty®: Black Ops</td>\n",
       "      <td>14.079452</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>917</td>\n",
       "      <td>17</td>\n",
       "      <td>39.99</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>27291</td>\n",
       "      <td>2839</td>\n",
       "      <td>68</td>\n",
       "      <td>12315</td>\n",
       "      <td>None</td>\n",
       "      <td>1295</td>\n",
       "      <td>165</td>\n",
       "      <td>585</td>\n",
       "      <td>165</td>\n",
       "      <td>Treyarch</td>\n",
       "      <td>Activision</td>\n",
       "      <td>Single-player,Multi-player,Co-op,Steam Achieve...</td>\n",
       "      <td>Action</td>\n",
       "      <td>Action,FPS,Zombies,Multiplayer,Shooter,Singlep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AppID                      Name  Release date  Estimated owners  \\\n",
       "29670  42700  Call of Duty®: Black Ops     14.079452         1500000.0   \n",
       "\n",
       "       Peak CCU  Required age  Price  DLC count Reviews  Windows  Mac  Linux  \\\n",
       "29670       917            17  39.99          4    None        1    0      0   \n",
       "\n",
       "       Metacritic score  User score  Positive  Negative  Achievements  \\\n",
       "29670                81           0     27291      2839            68   \n",
       "\n",
       "       Recommendations Notes  Average playtime forever  \\\n",
       "29670            12315  None                      1295   \n",
       "\n",
       "       Average playtime two weeks  Median playtime forever  \\\n",
       "29670                         165                      585   \n",
       "\n",
       "       Median playtime two weeks Developers  Publishers  \\\n",
       "29670                        165   Treyarch  Activision   \n",
       "\n",
       "                                              Categories  Genres  \\\n",
       "29670  Single-player,Multi-player,Co-op,Steam Achieve...  Action   \n",
       "\n",
       "                                                    Tags  \n",
       "29670  Action,FPS,Zombies,Multiplayer,Shooter,Singlep...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvec_df= pd.DataFrame(count_vector.toarray(), index=df_orig.index, columns=count_vectorizer.get_feature_names_out())\n",
    "df_orig[df_orig['AppID'] == 42700]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action                   1\n",
       "adventure                1\n",
       "co-op                    1\n",
       "cold war                 1\n",
       "controller               1\n",
       "first-person             1\n",
       "fps                      1\n",
       "gore                     1\n",
       "great soundtrack         1\n",
       "horror                   1\n",
       "linear                   1\n",
       "massively multiplayer    1\n",
       "military                 1\n",
       "multiplayer              1\n",
       "online co-op             1\n",
       "shooter                  1\n",
       "singleplayer             1\n",
       "story rich               1\n",
       "war                      1\n",
       "zombies                  1\n",
       "Name: 29670, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying tags are correctly processed by vectorizer\n",
    "countvec_df.loc[29670] # CoD Black Ops \n",
    "countvec_df.loc[29670][countvec_df.loc[29670] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_words = [x[0] for x in words_sorted]\n",
    "tfidf_slice = tfidf_df[selection_words]\n",
    "tfidf_slice.sort_values(selection_words, ascending=False).round(decimals=2).head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec embedding for Tags feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the embedding for the tags is an average of the tags for a given game. This results in d-dimensional feature embedding where d is the numer of dimensions specified in word2vec training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: process hyphenated and multi-word tags. Treat as one phrase by subbing dashes and spaces with an underline\n",
    "\n",
    "todo: tuning: what do the parameters do? what can be tweaked? what is desired?\n",
    "\n",
    "todo: CBOW vs CSkipGram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "class s_word2vec:\n",
    "# model_name = \"100features_1minwords_10context\"\n",
    "    def __init__(self):\n",
    "        self.model:gensim.models.Word2Vec = None\n",
    "        self.num_features = 100# Word vector dimensionality\n",
    "        self.min_word_count = 1  # Minimum word count\n",
    "        self.context = 10 # Context window size\n",
    "        self.model_name = f'{self.num_features}-feat_{self.min_word_count}-minwords_{self.context}-context'\n",
    "\n",
    "        self.num_workers = 8  # Number of threads to run in parallel\n",
    "        self.downsampling = 1e-3  # Downsample setting for frequent words\n",
    "\n",
    "    def _init_sims(self, model):\n",
    "        # If you don't plan to train the model any further, calling\n",
    "        # init_sims will make the model much more memory-efficient.\n",
    "        print(\"get_mean_vector is deprecated. Use get_vector(key, norm=True) instead\")\n",
    "        self.model.init_sims(replace=True)\n",
    "\n",
    "    def load_or_train_model(self):\n",
    "        if check_file_exists(self.model_name):\n",
    "            print(\"Loading saved model: \", self.model_name)\n",
    "            self.model = gensim.models.Word2Vec.load(self.model_name)\n",
    "            self._init_sims(self.model)\n",
    "\n",
    "        else:\n",
    "            # Code from:\n",
    "            # https://www.kaggle.com/competitions/word2vec-nlp-tutorial/overview\n",
    "\n",
    "            print(\"Training model...\")\n",
    "            self.model = gensim.models.Word2Vec(\n",
    "                sentences,\n",
    "                workers=self.num_workers,\n",
    "                vector_size=self.num_features,\n",
    "                min_count=self.min_word_count,\n",
    "                window=self.context,\n",
    "                sample=self.downsampling,\n",
    "            )\n",
    "            # It can be helpful to create a meaningful model name and\n",
    "            # save the model for later use. You can load it later using Word2Vec.load()\n",
    "            self.model.save(self.model_name)\n",
    "\n",
    "\n",
    "tags_w2v_model = s_word2vec()\n",
    "tags_w2v_model.load_or_train_model()\n",
    "model:gensim.models.Word2Vec = tags_w2v_model.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector of the tag 'singleplayer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = model.wv.get_mean_vector(sentences[9][1:])\n",
    "model.wv.similar_by_vector(sent, topn=len(sentences[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.wv.index_to_key))\n",
    "print(model.wv.index_to_key[3])\n",
    "model.wv['action'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing word2vec tag vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TSNE we can visualize the clustering of similar word vectors in word2vec model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "# conda install adjustText::conda-forge\n",
    "from adjustText import adjust_text\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\"\"\" Code for graphing from:\n",
    "    https://github.com/arsena-k/Word2Vec-bias-extraction/blob/master/Part_A_W2V_training_performance_exploring.ipynb\n",
    "\"\"\"\n",
    "def tsne_plot(words, vectors, iterations, seed, title):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    # you may need to tune these, epsecially the perplexity. \n",
    "    tsne_model = TSNE(\n",
    "        perplexity=7,\n",
    "        n_components=2,\n",
    "        init=\"pca\",\n",
    "        max_iter=iterations,\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    new_values = tsne_model.fit_transform(np.asarray(vectors))\n",
    "    # pca = PCA(2, svd_solver='full', random_state=42)\n",
    "    # new_values = pca.fit_transform(np.asarray(vectors))\n",
    "\n",
    "    x,y, texts = [],[],[]\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        texts.append( plt.text(\n",
    "                s=words[i],\n",
    "                #  xy=(x[i], y[i]),\n",
    "                x=x[i], y=y[i],\n",
    "                #  xytext=(x[i] + 0.1, y[i] - 0.2),\n",
    "                #   xytext=(5, 2),\n",
    "                #  textcoords='offset points',\n",
    "                ha=\"center\", va=\"center\",))\n",
    "    adjust_text(\n",
    "        texts,\n",
    "        expand=(6,5),\n",
    "        explode_radius=(15),\n",
    "        avoid_self=False,\n",
    "        max_move=(13,13),\n",
    "        force_text=(4,5),\n",
    "        force_explode=(5,5),\n",
    "        # force_static=(10,15),\n",
    "        # pull_threshold=20,\n",
    "        # force_pull=(0.1,0.1),\n",
    "        arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0.08\"),\n",
    "    )\n",
    "    plt.ylabel(\"Latent Dimension 1\")\n",
    "    plt.xlabel(\"Latent Dimension 2\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "my_word_list, my_word_vectors, label = [], [], []\n",
    "\n",
    "for i in model.wv.index_to_key:\n",
    "    try:\n",
    "        if my_word_list not in my_word_list:\n",
    "            my_word_vectors.append(model.wv[i])\n",
    "            my_word_list.append(i)\n",
    "    except (\n",
    "        KeyError\n",
    "    ):  # if one of the words_to_explore is not in the model vocab, just skip it\n",
    "        continue\n",
    "\n",
    "tsne_plot(my_word_list, my_word_vectors, iterations=2000, seed=23, title=\"TSNE Visualization of Word-Vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averging word2vec vectors\n",
    "The tag vectors corresponding to each game from the word2vec model are averaged to prepare a 100 dimensional embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('action', topn=10)\n",
    "model.wv.similar_by_word('action', topn=10) # same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.index_to_key\n",
    "words[0:10]\n",
    "model.wv.most_similar('none') # this needs fixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    pre-normalizing will discard sentence length information\n",
    "    this should ignore differences in numbe of tags specified for each game\n",
    "    Pre-normalize doesnt matter if init_sims(replace=True) since it will\n",
    "    precompute normalized vectors.\n",
    "    Not clear what the point of post_normalize is. May be/not good for training\n",
    "    the regression model down the line.\n",
    "\"\"\"\n",
    "\n",
    "tags_vectors = [\n",
    "    model.wv.get_mean_vector(game, pre_normalize=False, post_normalize=False)\n",
    "    for game in sentences\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Number of games', len(tags_vectors))\n",
    "# model.wv.similar_by_vector(tags_vectors[0],topn=20)\n",
    "# np.mean(tags_vectors[0])\n",
    "# np.linalg.norm(tags_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tags'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vdf = pd.DataFrame(tags_vectors)\n",
    "assert w2vdf.shape[1] == tags_w2v_model.num_features\n",
    "w2vdf.columns = [f'w2v_embed_{i}' for i in range(tags_w2v_model.num_features)]\n",
    "w2vdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Tags columns and merging embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Trick to prevent this from executing twice \"\"\"\n",
    "try:\n",
    "    check_if_w2vdf_already_concat\n",
    "except NameError:\n",
    "    df.drop(columns=['Tags'])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = pd.concat([df, w2vdf], axis=1)\n",
    "    check_if_w2vdf_already_concat = 1\n",
    "\n",
    "# del check_if_w2vdf_already_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(X, labels, probabilities=None, parameters=None, ground_truth=False, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(10, 4))\n",
    "    labels = labels if labels is not None else np.ones(X.shape[0])\n",
    "    probabilities = probabilities if probabilities is not None else np.ones(X.shape[0])\n",
    "    # Black removed and is used for noise instead.\n",
    "    unique_labels = set(labels)\n",
    "    colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    # The probability of a point belonging to its labeled cluster determines\n",
    "    # the size of its marker\n",
    "    proba_map = {idx: probabilities[idx] for idx in range(len(labels))}\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "\n",
    "        class_index = np.where(labels == k)[0]\n",
    "        for ci in class_index:\n",
    "            ax.plot(\n",
    "                # X[ci, 0],\n",
    "                tags_w2v_model.model.wv.index2word[]\n",
    "                X[ci, 1],\n",
    "                \"x\" if k == -1 else \"o\",\n",
    "                markerfacecolor=tuple(col),\n",
    "                markeredgecolor=\"k\",\n",
    "                markersize=4 if k == -1 else 1 + 5 * proba_map[ci],\n",
    "            )\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    preamble = \"True\" if ground_truth else \"Estimated\"\n",
    "    title = f\"{preamble} number of clusters: {n_clusters_}\"\n",
    "    if parameters is not None:\n",
    "        parameters_str = \", \".join(f\"{k}={v}\" for k, v in parameters.items())\n",
    "        title += f\" | {parameters_str}\"\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import HDBSCAN\n",
    "X_train, X_test = train_test_split(tags_vectors, test_size=0.2, train_size=0.8, random_state=42, shuffle=True)\n",
    "\n",
    "hdb:HDBSCAN = HDBSCAN()\n",
    "hdb.fit(tags_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(hdb.probabilities_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "labels = hdb.labels_\n",
    "silhouette_avg = silhouette_score(tags_vectors, labels)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Silhouette Coefficient: {:.2f}\".format(silhouette_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(X_train, hdb.labels_, parameters=None, probabilities=hdb.probabilities_)\n",
    "# tags_w2v_model.model.wv.word_vec('indie')o\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot_hdb(words, vectors, iterations, seed, title):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    # you may need to tune these, epsecially the perplexity. \n",
    "    tsne_model = TSNE(\n",
    "        perplexity=7,\n",
    "        n_components=2,\n",
    "        init=\"pca\",\n",
    "        max_iter=iterations,\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    new_values = tsne_model.fit_transform(np.asarray(vectors))\n",
    "    df_umap = (\n",
    "        pd.DataFrame(new_values, columns=['x', 'y'])\n",
    "        .assign(cluster=lambda df: hdb.labels_.astype(str))\n",
    "        .query('cluster != \"-1\"')\n",
    "        .sort_values(by='cluster')\n",
    "    ).to_numpy()\n",
    "\n",
    "    x,y, texts = [],[],[]\n",
    "    for value in df_umap:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        texts.append( plt.text(\n",
    "                s=words[i],\n",
    "                #  xy=(x[i], y[i]),\n",
    "                x=x[i], y=y[i],\n",
    "                #  xytext=(x[i] + 0.1, y[i] - 0.2),\n",
    "                #   xytext=(5, 2),\n",
    "                #  textcoords='offset points',\n",
    "                ha=\"center\", va=\"center\",))\n",
    "    adjust_text(\n",
    "        texts,\n",
    "        expand=(6,5),\n",
    "        explode_radius=(15),\n",
    "        avoid_self=False,\n",
    "        max_move=(13,13),\n",
    "        force_text=(4,5),\n",
    "        force_explode=(5,5),\n",
    "        # force_static=(10,15),\n",
    "        # pull_threshold=20,\n",
    "        # force_pull=(0.1,0.1),\n",
    "        arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0.08\"),\n",
    "    )\n",
    "    plt.ylabel(\"Latent Dimension 1\")\n",
    "    plt.xlabel(\"Latent Dimension 2\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "my_word_list, my_word_vectors, label = [], [], []\n",
    "\n",
    "for i in model.wv.index_to_key:\n",
    "    try:\n",
    "        # if my_word_list not in my_word_list:\n",
    "        my_word_vectors.append(model.wv[i])\n",
    "        my_word_list.append(i)\n",
    "    except (\n",
    "        KeyError\n",
    "    ):  # if one of the words_to_explore is not in the model vocab, just skip it\n",
    "        continue\n",
    "# tsne_plot(my_word_list, my_word_vectors, iterations=1000, seed=23, title=\"TSNE Visualization of Word-Vectors\")\n",
    "len(my_word_list)\n",
    "model.wv.similar_by_vector(model.wv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Reviews Using Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4269 reveiws which we can analyze for sentiment. Using the Twitter Roberta model we get three scores (negative, neutral, positive) which are computed into a compound score using a simple weighting of [-1, 0, 1], respectively, and a dot product of the scores. These scores are then gathered and averaged into a single score for each game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please unzip the sentiment model from the google drive folder into the models directory.\n",
    "\n",
    "When unzipped, the models directory should contain the folder `twitter-roberta-base-sentiment-latest` with 5 files inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "\n",
    "\n",
    "def calculate_sentiment():\n",
    "    roberta_path = 'models/twitter-roberta-base-sentiment-latest'\n",
    "    MODEL = roberta_path  # f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    config = AutoConfig.from_pretrained(MODEL)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL);\n",
    "\n",
    "\n",
    "    def preprocess(text: str):\n",
    "        if (text.find(\"“\") != -1):\n",
    "            p = text.split(\"“\")\n",
    "            p = [x.split(\"”\")[0].strip() for x in p]\n",
    "            p = p[1:]\n",
    "        else:\n",
    "            # if it's just a single review or follows a different format\n",
    "            # then just treat the whole string as a review\n",
    "            p = [text]\n",
    "        return p\n",
    "\n",
    "    def calculate_compound_score(scores):\n",
    "        sentiment_probabilities = np.asarray(scores)\n",
    "        weights = np.array([-1, 0, 1], dtype=np.float32)\n",
    "        return np.dot(sentiment_probabilities, weights)\n",
    "\n",
    "\n",
    "    s = df_reviews[df_reviews.notna()]\n",
    "    s = s.apply(preprocess)\n",
    "    # Tweak batch to your system. \n",
    "    # Mem Usage: 10-50 is safe. ~25 may be fastest. Needs around 8gb ram.\n",
    "    #=========\n",
    "    batch_size = 25 \n",
    "    #=========\n",
    "    scores = []\n",
    "    for i in range(0, s.size, batch_size): # compute in batches\n",
    "        p = s[i:i + batch_size]\n",
    "        pretokenized = [review for row in p.tolist() for review in row] # create a list of reviews \n",
    "        # pretokenized = \"New WW2 Strategy Game Offers A Harrowing Look At Poland's Ill-Fated 1944 Uprising\"\n",
    "        # compute the tokens\n",
    "        encoded_input = tokenizer(\n",
    "            pretokenized, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_input)\n",
    "        # gather scores in each batch\n",
    "        scores.extend([calculate_compound_score(softmax(logits.numpy()))\n",
    "                      for logits in output.logits])\n",
    "\n",
    "\n",
    "    row_lengths = [len(reviews) for reviews in s.tolist()]\n",
    "    row_lengths\n",
    "    game_sentiments = np.split(scores, np.cumsum(row_lengths)) # review scores grouped by game\n",
    "\n",
    "    if(game_sentiments[-1].shape == (0,)):\n",
    "        game_sentiments = game_sentiments[:-1]\n",
    "\n",
    "    game_sentiments = [np.mean(x) for x in game_sentiments] # average the score for each game\n",
    "\n",
    "    df_review_scores = pd.Series(game_sentiments, index=s.index) # re-index\n",
    "\n",
    "    # Copy df_reviews to avoid overwriting\n",
    "    df_reviews_with_scores = df_reviews.copy()\n",
    "\n",
    "    # Assign scores to the corresponding indices in the new series\n",
    "    df_reviews_with_scores.loc[df_review_scores.index] = df_review_scores\n",
    "\n",
    "    print(df_reviews_with_scores)\n",
    "    return df_reviews_with_scores\n",
    "\n",
    "try:\n",
    "    df_reviews_with_scores = unpickle_model('df_reviews_with_scores-values')\n",
    "except:\n",
    "    print('No stored values found. Running fresh sentiment analysis.')\n",
    "    df_reviews_with_scores = calculate_sentiment() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_model('df_reviews_with_scores', df_reviews_with_scores, {'no':'values'})\n",
    "df_reviews_with_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test data extraction + Regression model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important metrics when determinng a game's success include the number of estimated owners, peak ccu, number of pos/neg reveiws, and price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df[['Estimated owners', 'Peak CCU', 'Positive', 'Negative', 'Price']])\n",
    "X = np.array(df.drop(columns=['AppID', 'Name', 'Estimated owners', 'Peak CCU', 'Positive', 'Negative', 'Price', 'Reviews', 'Notes', 'Developers', 'Publishers', 'Tags'], axis=1))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X[0,:]) # ensure all data is numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor is used to handle non-linear relationships between a game and the metrics we are predicting. MultiOutputRegressor provides easier setup for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A grid search will also be done on the hyperparemeters for the random forest regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 70% training data, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=52)\n",
    "X_train = pca.fit_transform(X_train_scaled)\n",
    "X_test = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Find the number of components for 80% variance\n",
    "n_components = np.argmax(cumulative_variance >= 0.875) + 1  # Add 1 because index starts at 0\n",
    "\n",
    "print(f\"Number of components to preserve 87.5% variance: {n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df.columns.to_list()\n",
    "# Create a mapping between component weights and feature names\n",
    "component_weights = pca.components_\n",
    "feature_weights_mapping = {}\n",
    "for i, component in enumerate(component_weights):\n",
    "  component_feature_weights = zip(feature_names, component)\n",
    "  sorted_feature_weight = sorted(\n",
    "      component_feature_weights, key=lambda x: abs(x[1]), reverse=True)\n",
    "  feature_weights_mapping[f\"Component {i+1}\"] = sorted_feature_weight\n",
    "  \n",
    "# Accessing feature names contributing to Principal Component\n",
    "print(\"Feature names contributing to Principal Components\")\n",
    "for feature, weight in feature_weights_mapping.items():\n",
    "  print(f\"{feature}: {weight[0:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer, this cell takes hours to complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_search = False\n",
    "grid_search = None\n",
    "if perform_search == True:\n",
    "      # perform a grid search on hyperparameters for random forest\n",
    "      # -1 to utilize all processors and speed up training time\n",
    "      rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "      model = MultiOutputRegressor(rf, n_jobs=-1)\n",
    "\n",
    "      param_grid = [\n",
    "      {'estimator__n_estimators': [20, 50, 100, 150, 200, 250],\n",
    "       'estimator__max_features': [1, 20, 'sqrt', 50, 70, 90, 110],\n",
    "       'estimator__max_depth': [None, 10, 20, 30, 40, 50]}\n",
    "      ]\n",
    "\n",
    "      grid_search = GridSearchCV(model, param_grid, n_jobs=-1)\n",
    "      grid_search.fit(X_train, y_train)\n",
    "\n",
    "      pickle_model(\"rf_gridsearch_obj\", grid_search, grid_search.best_params_, param_grid[0])\n",
    "      print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparams were a max branch depth of 50, a random subset of 70 features for splitting branches, and 150 estimators/trees for random forest. These parameters are the most infuential to model capacity, generalization, and computation. Other parameters like min_samples_split were ommitted from grid search since the default is adequte to recognize patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "if perform_search == True:\n",
    "    model = grid_search.best_estimator_\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2_score_values= r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "\n",
    "    # ['Estimated owners', 'Peak CCU', 'Positive', 'Negative', 'Price']\n",
    "    print(\"Test set Mean Squared Error:\", mse)\n",
    "    print(\"Test set Root Mean Squared Error:\", rmse)\n",
    "    print(\"Test set R2 Score:\", r2_score_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "\"\"\" You can download from link in README \"\"\"\n",
    "load_model = True\n",
    "pca_model_filename = 'rf_pca'\n",
    "pca_params = {'max_depth': 50, 'max_features': 70, 'n_estimators': 150}\n",
    "for s in pca_params.values():\n",
    "    pca_model_filename += f'-{s}'\n",
    "try:\n",
    "    if load_model != True:\n",
    "        assert 'Training model'\n",
    "    loaded_model = unpickle_model(pca_model_filename)\n",
    "    model_pca = loaded_model\n",
    "except:\n",
    "    rf_pca = RandomForestRegressor(random_state=42, n_jobs=-1, verbose=1, **pca_params)\n",
    "    model_pca = MultiOutputRegressor(rf_pca, n_jobs=-1)\n",
    "    model_pca.fit(X_train, y_train)\n",
    "    y_pred = model_pca.predict(X_test)\n",
    "    pickle_model('rf_pca', model_pca, pca_params) \n",
    "\n",
    "if perform_search == False:\n",
    "    y_pred = model_pca.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2_score_values= r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "\n",
    "    # ['Estimated owners', 'Peak CCU', 'Positive', 'Negative', 'Price']\n",
    "    print(\"Test set Mean Squared Error:\", mse)\n",
    "    print(\"Test set Root Mean Squared Error:\", rmse)\n",
    "    print(\"Test set R2 Score:\", r2_score_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, fields, field\n",
    "\n",
    "@dataclass\n",
    "class DataMinMax:\n",
    "    data:dict = field(default_factory=dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = [\"Estimated owners\", \"Peak CCU\", \"Positive\", \"Negative\", \"Price\"]\n",
    "calc: DataMinMax = DataMinMax()\n",
    "for i, label in enumerate(predict_labels):\n",
    "    calc.data[label] = {\n",
    "        \"min\": df_orig[label].min(),\n",
    "        \"max\": df_orig[label].max(),\n",
    "        \"r2\": r2_score_values[i],\n",
    "        \"rmse\": rmse[i],\n",
    "    }\n",
    "# owners = df_orig['Estimated owners']\n",
    "# calc.owners = (min())\n",
    "# du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a DataFrame\n",
    "rows = []\n",
    "for label in predict_labels:\n",
    "\n",
    "    fmt_int = lambda x: f\"{x:,.0f}\"\n",
    "    fmt_float = lambda x, precision=2: f\"{x:,.{precision}f}\"\n",
    "    min_val = calc.data[label][\"min\"]\n",
    "    max_val = calc.data[label][\"max\"]\n",
    "    rmse_val = calc.data[label][\"rmse\"]\n",
    "    r2_val = calc.data[label][\"r2\"]\n",
    "    range_val = max_val - min_val\n",
    "    range_percent = rmse_val * 100\n",
    "    prediction = rmse_val*range_val\n",
    "    rows.append({\n",
    "        \"Metric\": label,\n",
    "        \"Prediction\": fmt_float(prediction, 2),\n",
    "        \"Min\": fmt_float(min_val,2),\n",
    "        \"Max\": fmt_float(max_val),\n",
    "        \"RMSE\": fmt_float(rmse_val, 4),\n",
    "        \"R^2\": fmt_float(r2_val, 4),\n",
    "        \"Range (%)\": fmt_float(range_percent,2),\n",
    "\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df_result = pd.DataFrame(rows)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set Mean Squared Error: [5.53550695e-05 1.01822779e-05 3.49412680e-05 1.67333804e-04\n",
    " 1.09633784e-03]\n",
    "\n",
    "Test set Root Mean Squared Error: [0.0074401  0.00319097 0.00591111 0.01293576 0.03311099]\n",
    "\n",
    "Test set R2 Score: [0.76685888 0.31981091 0.94586848 0.62299915 0.46089451]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the R2 Score, which indicates the proportion of variance in the dependent variable that is predictable from the independent variables, the model is able to capture underlying patterns decently for the estimated owners, positive number of reviews, and negative number of reviews. This suggests that relationships between the features and target variables are relatively strong, making them easier to predict.\n",
    "\n",
    "This is logical. Game characteristics like developers, publishers, and categories will directly influence price and peak ccu  counts more so than the other target variables. Since these aren't taken into account during training to avoid too many feature encodings, the correlation between these characteristics makes them harder to predict. **This will help us assign a score to each prediction when defining a success rating.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the equation: **original_value = (normalized_value * (data_max - data_min)) + data_min**, let's calculate the rmse for each predicted value in the original data scale to gauge how good/bad the mse is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Max Values:                \n",
    "*   75,000,000 owners                      \n",
    "*   872,138 CCU                            \n",
    "*   964,983 Positive Reviews                 \n",
    "*   138,530 Negative Reviews                    \n",
    "*   $ 269.99                             \n",
    "\n",
    "\n",
    "Original Min Values:\n",
    "*   10,000 owners\n",
    "*   1 CCU\n",
    "*   0  Positive Reviews\n",
    "*   0  Negative Reviews\n",
    "*   $ 0.6456165345712968\n",
    "\n",
    "**range % determined by rsme/(max-min)**\n",
    "\n",
    "RMSE in original data range:\n",
    "*   567,933.0055858027 owners  (0.76% of the range)\n",
    "*   2,783.9614091764875 CCU (0.32% of range)\n",
    "*   5,704.1244660345665  Positive Reviews (0.59% of range)\n",
    "*   1,791.9903878277946  Negative Reviews (1.3% of range)\n",
    "*   $ 9.278048072328264 (3.4% of range)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1CD4EsTokInoL8rrk7tV9dBVteDf4sZ2l",
     "timestamp": 1731559683460
    }
   ]
  },
  "kernelspec": {
   "display_name": "steamgames",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
